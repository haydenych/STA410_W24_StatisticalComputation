{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f578ec",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4edc2e",
   "metadata": {},
   "source": [
    "# Sequential Importance Sampling for HMMs\n",
    "\n",
    "A simple version of a ***Normal-Normal Hidden Markov Model (HMM)*** for $t=1,\\cdots,T$ \n",
    "and a ***sequential importance sampling proposal*** for this ***HMM*** using the [slash distribution](https://en.wikipedia.org/wiki/Slash_distribution) are\n",
    "\n",
    "\n",
    "\\begin{align*}\n",
    "Y_t \\sim {} & N(X_t, \\sigma^2) \\quad\\;  \\text{(observed)} &&& \\tilde X_t = {} & \\tilde X_{t-1} + Z_t/U_t \\quad \\text{(slash distribution proposal)}\\\\\n",
    "X_t \\sim {} & N(X_{t-1}, 1) \\quad \\text{(unobserved)} &&& Z_t \\sim {} & N(0, 1)\\\\\n",
    "X_0 \\equiv {} & 0 \\equiv \\tilde X_0 &&&U_t \\sim {} & U(0, 1)\n",
    "\\end{align*}\n",
    "\n",
    "The ***sequential importance weight*** for the $j^{th}$ ***importance sampling proposal*** random variable (sequence) $\\tilde X_{1:T} \\equiv (\\tilde X_1, \\cdots, \\tilde X_t, \\cdots \\tilde X_T)$, where $j$ is not included in the notation for brevity, is\n",
    "\n",
    "\\begin{align*}\n",
    "\\require{cancel}\n",
    "   W_1^* = {} & \\frac{p_{X_1|Y_1}(\\tilde x_1|Y_1=y_1)}{\\tilde p_{\\tilde X_1}(\\tilde x_1)} \\\\\n",
    "   = {} &\\frac{p_{Y_1 | X_1}(y_1 | \\tilde x_1) p_{X_1}(\\tilde x_1) \\overset{\\text{normalization}}{\\cancel{/ p_{Y_1}(y_1)}}}{\\tilde p_{\\tilde X_1}(\\tilde x_1) } \\quad \\text{where the normalized importance weight of the $j^{th}$ sample proposals is } W_{1j} = \\frac{W_{1j}^*}{\\sum_j W_{1j}^*}\\\\\n",
    "    W_t^* = {} &  \\frac{p_{X_{1:t},Y_{1:t}}(\\tilde x_{1:t}, y_{1:t})/p_{Y_{1:t}}(y_{1:t})}{\\tilde p_{\\tilde X_{1:t}}(\\tilde x_{1:t})} \\\\\n",
    "   = {} & \\underbrace{\\left(\\frac{p_{X_{1:(t-1)},Y_{1:(t-1)}}(\\tilde x_{1:(t-1)}, y_{1:(t-1)})}{ \\tilde p_{\\tilde X_{1:(t-1)}}(\\tilde x_{1:(t-1)})  }\\right)}_{W^*_{t-1}} \\frac{p_{X_t|X_{t-1}}(\\tilde x_t | \\tilde x_{t-1})p_{Y_t|X_{t}}( y_t | \\tilde x_t)}{ \\tilde p_{\\tilde X_t | \\tilde X_{t-1}}(\\tilde x_t | \\tilde x_{t-1}) } \\frac{1}{\\underset{\\text{normalization}}{\\cancel{p_{Y_{1:t}}(y_{1:t})}}} \\quad \\text{again normalized over $j$ as } W_{jt} = \\frac{W_{jt}^*}{\\sum_j W_{jt}^*}\\\\\n",
    "   & {} \\text{with $\\tilde p_{\\tilde X_t | \\tilde X_{t-1}}(\\tilde x_t | \\tilde x_{t-1}) \\not =  p_{\\tilde X_t | \\tilde X_{t-1}}(\\tilde x_t | \\tilde x_{t-1})$ not cancelling though for the specification $\\tilde X \\sim N(\\tilde X_{t-1},1)$ they would.}\n",
    "\\end{align*}\n",
    "\n",
    "Complete the `calculate_SIS_weights` function so that the `SIS_wResampling` function and the code below executes ***sequential importance sampling with resampling*** (also called [***sequential importance resampling***](https://en.wikipedia.org/wiki/Particle_filter#Sequential_Importance_Resampling_(SIR)))\n",
    "for this ***HMM*** and ***slash proposal distribution*** specification.  \n",
    "\n",
    "*This problem is inspired by Chapter 6.3.2 **Sequential Monte Carlo** and particularly draws upon sections 6.3.2.5 **Particle Filters** on page 179, 6.3.2.4 **Sequential Importance Sampling for Hidden Markov Models** on pages 175-176, 6.3.2.3 **Weight Degeneracy, Rejuvenation, and Effective Sample Size**, and Example 6.3 **Slash Distribution** pages 165-166 of the Givens and Hoeting **Computational Statistics** textbook. [Errata Warning: the right side equation 6.33 on page 175 in section 6.3.2.4 **Sequential Importance Sampling for Hidden Markov Models** has the typo $f_t$ which should be $f_{t-1}$ and the left side of the equation is wrong and should either be $f_{t}(x_{1:t},y_t|y_{1:(t-1)})$, or the normalizing constant $p(y_t|y_{1:(t-1)})$ could be added as a denomenator on the right hand side, or the equation could have alternatively been specified in terms of joint distributions rather than conditional distributions as $f_{t}(x_{1:t},y_{1:t}) = f_{t-1}(x_{1:(t-1)},y_{1:(t-1)})p_x(x_t|x_{t-1})p_y(y_t|x_t)$, e.g., as is done [here](https://www.almoststochastic.com/2013/08/sequential-importance-sampling.html)]*.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11acecd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not edit this cell\n",
    "T,noise_to_signal = 100,5\n",
    "x,y = np.zeros(T+1),np.zeros(T+1)\n",
    "np.random.seed(9)\n",
    "x[0], y[0] = 0, x[0] + stats.norm.rvs(scale=noise_to_signal, size=1)\n",
    "for t in range(1,T+1):\n",
    "    x[t] = x[t-1] + stats.norm.rvs(size=1)\n",
    "    y[t] = x[t] + stats.norm(scale=noise_to_signal).rvs(size=1)\n",
    "plt.plot(x, label='Signal')\n",
    "plt.plot(y, label='Signal+Noise')\n",
    "plt.title(\"How well can the original signal be detected?\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644e0a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 500\n",
    "# T is the number of time points and we have one time series observation comprised of T time point observations\n",
    "# n above is the number of particles, i.e., importance sampling proposals, each a time series of length T \n",
    "# (There's actually T+1 points because X0=tildeX0=0)\n",
    "\n",
    "tilde_x, w_star, effective_sample_size = np.zeros((n,T+1)), np.ones((n,T+1)), np.ones(T+1)*n\n",
    "# tilde_x is the importance sampling proposals (i.e., stroed across rows)\n",
    "# w_star  is the unnormalized importance sampling proposal weights accumulated up to time t \n",
    "#         for each of the n proposals (i.e., stored down the columns)\n",
    "# effective_sample_size is what it sounds like and is calculated from SIS weights as in the code below\n",
    "\n",
    "# proposal distribution sampling and evaluation\n",
    "# https://en.wikipedia.org/wiki/Slash_distribution\n",
    "slash_pdf = lambda x: (1-np.exp(-x**2/2))/(x**2*np.sqrt(2*np.pi))\n",
    "slash_rvs = lambda n: stats.norm.rvs(size=n)/stats.uniform.rvs(size=n)\n",
    "\n",
    "# particle weights: COMPLETE THIS FUNCTION! When this fucntion works all the remaining code will work.\n",
    "def calculate_SIS_weights(y, tilde_x_t, tilde_x_t_minus_1, w_star_t_minus_1, proposal_pdf):\n",
    "    w_star_t = np.zeros(w_star_t_minus_1.shape)\n",
    "    # <complete>\n",
    "    return w_star_t\n",
    "\n",
    "# normalizing weights for resampling has a known problem which is avoided by this function\n",
    "# https://github.com/numpy/numpy/issues/8317\n",
    "def normalize(w):\n",
    "    pcond = True\n",
    "    while pcond:\n",
    "        w[w==min(w[:-1][w[:-1]>0])] = 0\n",
    "        # https://github.com/scipy/scipy/blob/v1.8.0/scipy/stats/_multivariate.py\n",
    "        # does automatically does this \"correction\" and subsequent `pcond` checks below\n",
    "        w[..., -1] = 1. - w[..., :-1].sum()\n",
    "        # annoyingly, this reassignment of `w[-1]` in `scipy.stats._multivariate.py` \n",
    "        # can cause proper `w` to break, e.g., producing a negative `w[-1]` or a `w.sum()`>1.\n",
    "        # to correct this error which `scipy.stats._multivariate.py` may introduce \n",
    "        # this code iteratively simplifies `w` via `w[w==min(w[:-1][w[:-1]>0])] = 0` above\n",
    "        # and the normalization below until the `pcond` checks in `_multivariate.py` will pass\n",
    "        w = w/np.sort(w)[::-1].sum()\n",
    "        # \"true for bad p\"\n",
    "        pcond = np.any(w < 0, axis=-1)\n",
    "        pcond |= np.any(w > 1, axis=-1)\n",
    "        pcond |= w[:-1].sum()>1\n",
    "    return w        \n",
    "\n",
    "# This is a helper function for particle filter rejuvenation\n",
    "# i.e., bootstrapping SIS according to the particle weights\n",
    "# i.e., converting SIS to SIR (i.e., SIS with resampling) \n",
    "def bootstrap_indices(ireps):\n",
    "    return np.concatenate([r*[i] for i,r in enumerate(ireps)]).flatten().astype(int)\n",
    "    \n",
    "def SIS_wResampling(y, tilde_x, w_star, slash_rvs, slash_pdf, n, T, R):\n",
    "    \n",
    "    # SIS extension loop\n",
    "    for t in range(1, T+1):\n",
    "\n",
    "        # extension of SIS proposal from `tilde_x[:,t-1]` to tilde_x[:,t]\n",
    "        tilde_x[:,t] = tilde_x[:,t-1] + proposal_rvs(n)\n",
    "        # SIS (cumulative) weights: YOU SHOULD HAVE COMPLETED THIS FUNCTION ABOVE!\n",
    "        w_star[:,t] = calculate_SIS_weights(y[t], tilde_x[:,t].copy(), tilde_x[:,t-1].copy(), \n",
    "                                            w_star[:,t-1].copy(), proposal_pdf = proposal_pdf)\n",
    "        # normalizing SIS weights for subsequent bootstrapping, i.e., particle filter rejuvenation\n",
    "        w_star_normalized = w_star[:,t].copy()\n",
    "        w_star_normalized = w_star_normalized/w_star_normalized.sum() # this \"should\" be sufficient\n",
    "        # but because of the issue noted above in `normalize` additional numeric correction is needed\n",
    "        w_star_normalized = normalize(w_star_normalized)  \n",
    "        effective_sample_size[t] = 1/(w_star_normalized**2).sum()\n",
    "        # sequence weights decay over time as a bad proposals at time t erode overal proposal quality\n",
    "        # the weights can be rejuvenated, however, by using a bootstrapping step in the partical filter\n",
    "        if (effective_sample_size[t]<R) or (t==T-1):\n",
    "            # bootstrap partical filter rejuvenation according to the current (normalized) SIS weights\n",
    "            bs_samp = stats.multinomial(n, p=w_star_normalized).rvs(size=1)[0]\n",
    "            tilde_x[:,:(t+1)] = tilde_x[bootstrap_indices(bs_samp),:(t+1)]\n",
    "            w_star[:,t] = 1 # because the weighted importance samples approximate the true\n",
    "            # distribuition, thus they are taken is iid samples from the true distribution\n",
    "    return tilde_x, effective_sample_size\n",
    "\n",
    "np.random.seed(20)            \n",
    "tilde_x, effective_sample_size = SIS_wResampling(y.copy(), tilde_x.copy(), w_star.copy(),\n",
    "                                                 proposal_rvs, proposal_pdf, n, T, n/10)\n",
    "            \n",
    "def plotit():\n",
    "    fig,ax = plt.subplots(2,1, figsize=(15,10))\n",
    "    for i in range(n):\n",
    "        ax[0].plot(tilde_x[i,:], color='gray')\n",
    "    ax[0].plot(x, 'k:', label='latent HMM')\n",
    "    ax[0].plot(y, 'r-', label='Observation')\n",
    "    ax[0].plot(tilde_x.mean(axis=0), 'w-', label='SIS HMM estimate')\n",
    "    ax[0].legend(facecolor='gray', framealpha=.5)\n",
    "    ax[1].plot(effective_sample_size)\n",
    "    ax[1].set_title(\"Effective Sample Size\");\n",
    "plotit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b89743c",
   "metadata": {},
   "source": [
    "## Hints:\n",
    "\n",
    "- The questions below are designed to help you complete the necessary code.\n",
    "    - Only update the `calculate_SIS_weights` method.  \n",
    "    - Nothing else in the code should be changed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a95297",
   "metadata": {},
   "source": [
    "### Problem 3 question 0-11 (2 points, 1/6 point each)\n",
    "\n",
    "0. What kind of methodology is implemented by the `SIS_wResampling` function?\n",
    "\n",
    "- (A) Bayesian MCMC analysis\n",
    "- (B) Optimization\n",
    "- (C) Particle filtering\n",
    "- (D) Rejection sampling\n",
    "\n",
    "1. Which of the following does `stats.norm(loc=tilde_x_t, scale=noise_to_signal).pdf(y)` represent?\n",
    "\n",
    "- (A) $p_{Y_t|X_{t}}( y_t | \\tilde x_t)$\n",
    "- (B) $p_{X_t|X_{t-1}}(\\tilde x_t | \\tilde x_{t-1})$\n",
    "- (C) $\\tilde p_{\\tilde X_t | \\tilde X_{t-1}}(\\tilde x_t | \\tilde x_{t-1})$\n",
    "- (D) None of the above\n",
    "\n",
    "2. Which of the following can `stats.norm(loc=tilde_x_t, scale=noise_to_signal).pdf(y)` represent?\n",
    "\n",
    "- (A) $p_{Y_1 | X_1}(y_1 | \\tilde x_1)$\n",
    "- (B) $p_{X_1}(\\tilde x_1)$\n",
    "- (C) $\\tilde p_{\\tilde X_1}(\\tilde x_1)$\n",
    "- (D) None of the above\n",
    "\n",
    "4. Which of the following does `stats.norm(loc=tilde_x_t_minus_1, scale=1).pdf(tilde_x_t)` represent?\n",
    "\n",
    "- (A) $p_{Y_t|X_{t}}( y_t | \\tilde x_t)$\n",
    "- (B) $p_{X_t|X_{t-1}}(\\tilde x_t | \\tilde x_{t-1})$\n",
    "- (C) $\\tilde p_{\\tilde X_t | \\tilde X_{t-1}}(\\tilde x_t | \\tilde x_{t-1})$\n",
    "- (D) None of the above\n",
    "\n",
    "\n",
    "4. Which of the following can `stats.norm(loc=tilde_x_t_minus_1, scale=1).pdf(tilde_x_t)` represent?\n",
    "\n",
    "- (A) $p_{Y_1 | X_1}(y_1 | \\tilde x_1)$\n",
    "- (B) $p_{X_1}(\\tilde x_1)$\n",
    "- (C) $\\tilde p_{\\tilde X_1}(\\tilde x_1)$\n",
    "- (D) None of the above\n",
    "\n",
    "5. Which of the following does `proposal_pdf(tilde_x_t-tilde_x_t_minus_1)` represent?\n",
    "\n",
    "- (A) $p_{Y_t|X_{t}}( y_t | \\tilde x_t)$\n",
    "- (B) $p_{X_t|X_{t-1}}(\\tilde x_t | \\tilde x_{t-1})$\n",
    "- (C) $\\tilde p_{\\tilde X_t | \\tilde X_{t-1}}(\\tilde x_t | \\tilde x_{t-1})$\n",
    "- (D) None of the above\n",
    "\n",
    "6. Which of the following can `proposal_pdf(tilde_x_t-tilde_x_t_minus_1)` represent?\n",
    "\n",
    "- (A) $p_{Y_1 | X_1}(y_1 | \\tilde x_1)$\n",
    "- (B) $p_{X_1}(\\tilde x_1)$\n",
    "- (C) $\\tilde p_{\\tilde X_1}(\\tilde x_1)$\n",
    "- (D) None of the above\n",
    "\n",
    "7. What is $\\frac{p_{X_{1:(t-1)},Y_{1:(t-1)}}(\\tilde x_{1:(t-1)}, y_{1:(t-1)})}{ \\tilde p_{\\tilde X_{1:(t-1)}}(\\tilde x_{1:(t-1)})  }$ equal to?\n",
    "\n",
    "- (A) `w_star_t`\n",
    "- (B) `w_star_t_minus_1`\n",
    "- (C) `w_star_t * w_star_t_minus_1`\n",
    "- (D) None of the above\n",
    "\n",
    "\n",
    "8. Why doesn't the time series match the observed data?\n",
    "\n",
    "- (A) The model assumes noisy data and estimates the latent trend in spite of the noise\n",
    "- (B) More data is required since this is just a single (multivariate time series) observation \n",
    "- (C) The effective sample size is too low and the particles are thus not sufficiently diverse\n",
    "- (D) The model just does not seem to work very well as currently specified\n",
    "\n",
    "9. Why is the predicted trend line smoother toward the end of the time series?\n",
    "\n",
    "- (A) Rejuvenating effective sample size by bootstrapping filters out early sequence diversity \n",
    "- (B) There are more proposal sequences towards then end of the time series versus the beginning\n",
    "- (C) The data is more volatile towards the beginning of the time series versus versus the end\n",
    "- (D) It's not really less smooth and just looks that way due to run to run variation\n",
    "\n",
    "10. If the diversity of the sequences sequences resampled by bootstrapping is reduced due to sample multiplicity from bootstrap sampling, why does the effective sample size still end to be close to the original number of specified particles `n`?\n",
    "\n",
    "- (A) The effective samples size calculation is larger for more homogenous weights\n",
    "- (B) The weights are rejuvenated to 1 through the bootstrap approximation to the true distribution\n",
    "- (C) Both of the above\n",
    "- (D) None of the above\n",
    "\n",
    "11. What is the true cumulative MSE of the bootstrap particle filter estimator?\n",
    "\n",
    "$$\\frac{\\sum_{t=1}^T\\left(\\frac{\\sum_{j=1}^n \\tilde x_{jt}}{n} - x_t\\right)^2}{n}$$ \n",
    "\n",
    "*Note: do not include $t=0$ in your calculation as that's just the inititalization.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04abe5d5",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# p3q0-q11: 1/6 point each [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" based on the choices above]\n",
    "p3q0 = \"\"#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p3q1 = \"\"#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p3q2 = \"\"#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p3q3 = \"\"#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p3q4 = \"\"#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p3q5 = \"\"#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p3q6 = \"\"#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p3q7 = \"\"#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p3q8 = \"\"#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p3q9 = \"\"#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p3q10 = \"\"#<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "# p2q11: [format: `float`]\n",
    "p3q11 = #\n",
    "# This cell will produce a runtime error until the `p1q11` variable is assigned a value"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
