{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06837861",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Unless a problem instructs differently, you may use any functions available from the following library imports\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import sklearn\n",
    "import statsmodels.api as sm\n",
    "from scipy.special import expit as invlogit\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e2e48",
   "metadata": {},
   "source": [
    "# Problem 2 (5 points)\n",
    "\n",
    "Provide a model fit that is robust against outliers by defining the function `huber_SLR(x, y, c, K=10, eps=1e-7)` (for simple linear regression) which implements ***M estimation*** for ***Huber loss*** with the ***IRLS*** algorithm where the weight of a data point is $1$ if $|y_i-x_i^t\\beta^{(t)}| \\leq c$ and $0$ otherwise.\n",
    "\n",
    "***Hints:*** \n",
    "\n",
    "- Your `huber_SLR` function will be tested directly using data simiar to the example below.\n",
    "- Use the `OLS` function rather than the `WLS` function by subsetting the data to only the points with weight $1$.\n",
    "- This algorithm is specified in the course notes as well as in Keith Knight's STA410 [notes14.pdf document](https://q.utoronto.ca/courses/296804/files?preview=25407629)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1364a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100\n",
    "np.random.seed(1)\n",
    "x = stats.norm.rvs(size=n)\n",
    "y = 5*x + (1+np.abs(x))*stats.norm().rvs(size=n) \n",
    "fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "ax[0].plot(x,y,'.', label=\"Clean Data\")\n",
    "\n",
    "# https://www.statsmodels.org/dev/generated/statsmodels.regression.linear_model.OLS.html\n",
    "X = sm.add_constant(x)\n",
    "model = sm.OLS(y,X)\n",
    "fit = model.fit()\n",
    "support = np.linspace(-3,3,20)\n",
    "ax[0].plot(support,fit.predict(sm.add_constant(support)),\n",
    "           label=\"Clean Data Model Fit\")\n",
    "ax[0].legend()\n",
    "\n",
    "n_corrupted = 10\n",
    "np.random.shuffle(x[:n_corrupted])\n",
    "ax[1].plot(support,fit.predict(sm.add_constant(support)),\n",
    "           label=\"Clean Data Model Fit\")\n",
    "ax[1].plot(x,y,'.', label=\"Corrupted Data\")\n",
    "X = sm.add_constant(x)\n",
    "model = sm.OLS(y,X)\n",
    "fit = model.fit()\n",
    "support = np.linspace(-3,3,20)\n",
    "ax[1].plot(support,fit.predict(sm.add_constant(support)),\n",
    "           label=\"Corrupted Data Model Fit\")\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ea6ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_SLR(x, y, c, K=10, eps=1e-7)\n",
    "    '''\n",
    "        Fits a simple linear regression y=ax+b using \n",
    "        huber loss with arbitrary tuning parameter c\n",
    "        \n",
    "        x:   (np.array)  independent variable\n",
    "        y:   (np.array)  dependent variable\n",
    "        c:   (float)     |y_i-yhat_i|>c makes w_i=0; otherwise, w_i=1\n",
    "        K:   (int)       maximum IRLS steps\n",
    "        eps: (float)     stopping criterion returns IRLS fit at step k\n",
    "                         if ||(a_k,b_k)-(a_{k-1},b_{k-1})||_2^2 < eps\n",
    "                         \n",
    "        returns IRLS fit (statsmodels OLS) object\n",
    "                after K steps of when eps stopping criterion is met\n",
    "    '''\n",
    "\n",
    "    X = sm.add_constant(x); model = sm.OLS(y,X); fit = model.fit()\n",
    "    params = fit.params\n",
    "    \n",
    "    # Complete the K-step Huber loss IRLS algorithm updating `fit`\n",
    "    # incorporating an eps-based easly stopping criterion\n",
    "    \n",
    "    return fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59626d3e",
   "metadata": {},
   "source": [
    "## Problem 2 question 0-2 (2 points)\n",
    "\n",
    "0-2. Your `huber_SLR` will be tested on the data above for various choices of `c`, `K`, and `eps`.\n",
    "\n",
    "- You do not need to assign any variables for this problem -- your `huber_SLR` function will be called directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05395571",
   "metadata": {},
   "source": [
    "## Problem 2 question 3 (1 point)\n",
    "\n",
    "3. Which of the following is the smallest integer value for $c$ which first makes the simple linear regression fit of the `huber_SLR` extremely similar to the \"Clean Data Model Fit\" for the data ?\n",
    "\n",
    "    1. 1\n",
    "    2. 2\n",
    "    3. 3\n",
    "    4. 4\n",
    "\n",
    "***Hint:*** if you replace `ax[1].legend()` with \n",
    "\n",
    "```python\n",
    "huber_fit = huber_SLR(x,y,c=2,K=10)\n",
    "ax[1].plot(support,huber_fit.predict(sm.add_constant(support)),\n",
    "           label=\"Huber Loss Corrupted Data Model Fit\")\n",
    "ax[1].legend()\n",
    "```\n",
    "\n",
    "in the plotting demonstration code above you can see the simple linear regression line fit with the ***Huber loss*** function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bdab61",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 1.0 point [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" based on the choices above]\n",
    "p2q3 = #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "# Uncomment the above and keep each only either \"A\" or \"B\" or \"C\" or \"D\"\n",
    "\n",
    "# This cell will produce a runtime error until the `p2q3` variable is assigned a value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f0660f",
   "metadata": {},
   "source": [
    "## Problem 2 question 4-6 (1 point)\n",
    "\n",
    "4-6. Define a new function `huber_MLR` which generalizes the simpler linear regression function `huber_SLR` to accept a multivariate design matrix `X` rather than a vector `x`. When defining `huber_MLR` follow the specifications given in the starter code below.\n",
    "\n",
    "- You do not need to assign any variables for this problem -- your `huber_MLR` function will be tested directly for some design matrix `X` and various choices of `c`, `K`, and `eps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b8a8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_MLR(x, y, c, K=10, eps=1e-7):\n",
    "    '''\n",
    "        Fits a multivariate linear regression y = X beta using \n",
    "        huber loss with arbitrary tuning parameter c\n",
    "        \n",
    "        X(n,p): (np.array)  design matrix (intercept will not be added)\n",
    "        y(n,):  (np.array)  dependent variable\n",
    "        c:      (float)     |y_i-yhat_i|>c makes w_i=0; otherwise, w_i=1\n",
    "        K:      (int)       maximum IRLS steps (default K=10)\n",
    "        eps:    (float)     stopping criterion returns IRLS fit at step k\n",
    "                            if ||(a_k,b_k)-(a_{k-1},b_{k-1})||_2^2 < eps (default eps=1e-7)\n",
    "                         \n",
    "        returns IRLS fit (statsmodels OLS) object\n",
    "                after K steps of when eps stopping criterion is met\n",
    "    '''\n",
    "\n",
    "    # Complete the K-step Huber loss IRLS algorithm updating `fit`\n",
    "    # incorporating an eps-based easly stopping criterion\n",
    "    \n",
    "    model = sm.OLS(y,X); fit = model.fit()\n",
    "    params = fit.params\n",
    "    \n",
    "    return fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfc60a8",
   "metadata": {},
   "source": [
    "## Problem 2 questions 7-8 (1 point)\n",
    "\n",
    "7. What is true about the ***M estimation*** for ***Huber loss*** in problem 2 and logistic regression model fitting in problem 1?\n",
    "\n",
    "    1. They both substitue ***Fisher information*** for the expected value of the ***Hessian***\n",
    "    2. Problem 2 specifies a minimization problem while problem 1 specifies a maximization problem\n",
    "    3. Problem 1 is implemented using an ***IRLS*** algorithm while ***M estimation*** for ***Huber loss*** in problem 2 is not\n",
    "    4. All of the above\n",
    "\n",
    "\n",
    "8. For ***Huber loss*** fit with ***M estimation*** as above, which of the following is the same as $E[X^TWX]$, where \n",
    "\n",
    "   $$W_{ii}=\\left\\{\\begin{array}{ll} 1 & |y_i-x_i^T\\beta|\\leq c\\\\0&\\text{otherwise} \\end{array}\\right. \\quad \\text{ and } \\quad W_{ij}=0 \\text{ for } i\\neq j$$ \n",
    "\n",
    "   and $c$ is the ***Huber loss*** function parameter and $y_i$ is assumed to be independently and identically distributed for all $i$?\n",
    "\n",
    "    1. $\\Pr(|y_i-x_i^T\\beta|\\leq c)X^TX$ \n",
    "    2. ***expected Fisher Information***\n",
    "    3. ***observed Fisher Information***\n",
    "    4. The inverse of the negative ***Hessian*** matrix\n",
    "    5. All of the above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33a475",
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# 0.5 points each [format: `str` either \"A\" or \"B\" or \"C\" or \"D\" or \"E\" based on the choices above]\n",
    "p2q7 = #<\"A\"|\"B\"|\"C\"|\"D\"> \n",
    "p2q8 = #<\"A\"|\"B\"|\"C\"|\"D\"|\"E\"> \n",
    "# Uncomment the above and keep each only either \"A\" or \"B\" or \"C\" or \"D\" or \"E\"\n",
    "\n",
    "# This cell will produce a runtime error until the `p2q7` and `p2q8` variables are assigned values"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
